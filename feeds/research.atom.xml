<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>markpp.dk - research</title><link href="http://markpp.github.io/" rel="alternate"></link><link href="http://markpp.github.io/feeds/research.atom.xml" rel="self"></link><id>http://markpp.github.io/</id><updated>2018-04-29T17:49:00+02:00</updated><subtitle>Exploring Applications of Computer Vision and Machine Learning</subtitle><entry><title>Human-Robot Interaction conference in Chicago, 2018</title><link href="http://markpp.github.io/hri-2018.html" rel="alternate"></link><published>2018-04-29T17:49:00+02:00</published><updated>2018-04-29T17:49:00+02:00</updated><author><name>Mark Philip Philipsen</name></author><id>tag:markpp.github.io,2018-04-29:/hri-2018.html</id><summary type="html">&lt;p&gt;Some notes from HRI conference&lt;/p&gt;</summary><content type="html">&lt;p&gt;I attended the 2018 conference on Human-Robot Interaction. The primary reason was to present work done by VGIS students I had supervised during the autumn semester of 2017. Secondly, to gather inspiration for the new Grand Solutions - Augmented Cellular Meat Production (ACMP) project I was part of. Not that I would spend much more time on the HRI aspects but AAU had just acquired a new PhD that would work on this aspect of the ACMP project and I would like to be somewhat up-to-date on the topic.&lt;/p&gt;
&lt;h2&gt;General take-ways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Test on the actual end users - use user study experts for this&lt;/li&gt;
&lt;li&gt;Precise knowledge of objects and actors locations is needed - how do we get that?&lt;/li&gt;
&lt;li&gt;Collaborating with real industrial robots - No one at HRI was looking specifically at this&lt;/li&gt;
&lt;li&gt;Possible collaborator in how robots are received in the workplace - Institut for Uddannelse og PÃ¦dagogik(http://edu.au.dk/)&lt;/li&gt;
&lt;li&gt;VR is seen as mature, AR not yet but will be soon and is therefore also more interesting from research point of view&lt;/li&gt;
&lt;li&gt;Nice explanations of mixed reality - "Making the hidden visible" or "exposing the hidden"&lt;/li&gt;
&lt;li&gt;Nothing is completely autonomous - the degree of interaction just varies&lt;/li&gt;
&lt;li&gt;Infrastructure is essential for efficient collaboration e.g. lane lines and signals&lt;/li&gt;
&lt;li&gt;Adapt the systems to the expertise level of the user to improve efficiency and avoid frustration - measure expertise based on tracks (shows clear difference)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Keynotes&lt;/h2&gt;
&lt;p&gt;Steve Cousins' Keynote - Building a Service Robotic Business, Challenges from the Field&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use case is key, is it an aspirin or a vitamin&lt;/li&gt;
&lt;li&gt;Robots help avoid monday models&lt;/li&gt;
&lt;li&gt;Danger&lt;/li&gt;
&lt;li&gt;Reduce impact of turnover&lt;/li&gt;
&lt;li&gt;Other things than savings on workers hit the bottomline&lt;/li&gt;
&lt;li&gt;Relay for transport between cells?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;David Mindell's Keynote - Autonomy in human environments&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is autonomy? Never complete autonomy&lt;/li&gt;
&lt;li&gt;Use of infrastructure to facilitate safe and efficient collaboration e.g. TLs
People &amp;lt;-&amp;gt; robots &amp;lt;-&amp;gt; infrastructure &amp;lt;-&amp;gt; people&lt;/li&gt;
&lt;li&gt;Detect expertise from precise tracks&lt;/li&gt;
&lt;li&gt;Knowledge of precise location is essential&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Specific Research&lt;/h2&gt;
&lt;p&gt;Titles and short summaries of presented works that would be worth looking further into.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Teaching users to remote control robot using scaffolding. dynamic curves controls the amount of scaffolding. Used to train a human operator, could it be used the other way?&lt;/li&gt;
&lt;li&gt;"Its all in your head". Priming the expectations of the user. Large impact on the perception of the product.&lt;/li&gt;
&lt;li&gt;Projecting robot intentions into the physical world. Highlighting the robots next move. Gamification.&lt;/li&gt;
&lt;li&gt;Human-robot handover - Vary based on user experience level. Safety concerns solve by augmenting to show robot capabilities.&lt;/li&gt;
&lt;li&gt;"A framework for robot generated mixed reality deixis" - New classes are possible in MR, annotations with e.g. arrows&lt;/li&gt;
&lt;li&gt;"Transfer learning for robot navigation" - RNN learns to control robot through forrest. Sim-to-real.&lt;/li&gt;
&lt;li&gt;"Training robots to acquire new skills" - RL PyBullet&lt;/li&gt;
&lt;li&gt;Task planning in VR&lt;/li&gt;
&lt;li&gt;Exposing the hidden&lt;/li&gt;
&lt;li&gt;"Learning grasp from kinaesthetic demonstrations and mental simulations" - map between object and contact point, model hand/tool, evaluate grasp before execution&lt;/li&gt;
&lt;li&gt;"Designing gripper by looking at what/how humans grasp" - record video of grasps, categorise, rank&lt;/li&gt;
&lt;li&gt;"Teaching users to remote control robot using scaffolding" - dynamic curves controls the amount of scaffolding. Used to train a human operator, could it be used the other way?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;its all in your head&lt;/h2&gt;
&lt;p&gt;Priming the expectations of the user
Main poster session&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="pic1" src="../images/chicago2018/poster_session.jpg" title="Poster session"&gt;&lt;/p&gt;
&lt;h2&gt;"Virtual, Augmented, and Mixed Reality for Human-Robot Interaction" workshop poster session with VGIS students' poster&lt;/h2&gt;
&lt;p&gt;&lt;img alt="pic2" src="../images/chicago2018/vgis_student_poster.jpg" title="VGIS Students' Poster"&gt;&lt;/p&gt;</content><category term="research"></category><category term="human-machine interaction"></category><category term="conference"></category></entry></feed>