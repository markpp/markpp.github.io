<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Adaptive Slaugther Robots - research</title><link href="http://markpp.github.io/" rel="alternate"></link><link href="http://markpp.github.io/feeds/research.atom.xml" rel="self"></link><id>http://markpp.github.io/</id><updated>2017-02-23T17:49:00+01:00</updated><entry><title>Stay abroad</title><link href="http://markpp.github.io/research-abroad.html" rel="alternate"></link><published>2017-01-23T17:49:00+01:00</published><updated>2017-02-23T17:49:00+01:00</updated><author><name>Mark Philip Philipsen</name></author><id>tag:markpp.github.io,2017-01-23:/research-abroad.html</id><summary type="html">&lt;p&gt;Overview of relevant places to visit as part of the PhD&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Candidate universities&lt;/h3&gt;
&lt;p&gt;-&lt;/p&gt;
&lt;h3&gt;Candidate companies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SCOTT New Zealand&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Funding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="travel"></category><category term="company"></category><category term="university"></category><category term="research"></category></entry><entry><title>Research areas</title><link href="http://markpp.github.io/research-areas.html" rel="alternate"></link><published>2017-01-23T17:49:00+01:00</published><updated>2017-02-23T17:49:00+01:00</updated><author><name>Mark Philip Philipsen</name></author><id>tag:markpp.github.io,2017-01-23:/research-areas.html</id><summary type="html">&lt;p&gt;Overview of the research areas that are of relevance to my PhD&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Reinforcement learning&lt;/h2&gt;
&lt;p&gt;Appropriate actions in a given state are learned from feedback in the form of rewards and penalties. Exploration and exploitation are the mechanisms for trying new actions and for xx, respectively.
- Self-learning framework which can be applied to several similar robot control problems. &lt;a href="https://arxiv.org/abs/1312.5602"&gt;DeepMind, Playing Atari with Deep Reinforcement Learning&lt;/a&gt;&lt;a href="http://www.davidqiu.com:8888/research/nature14236.pdf"&gt;DeepMind, Human-level control through deep reinforcement learning&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Continuous(online) learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Continuously adjusting a trained model while in use, based on feedback.&lt;/li&gt;
&lt;li&gt;Extending a pretrained model with new functionality, e.g. adding an additional class to a classifier without retraining using the original dataset.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Hybrid intelligence&lt;/h2&gt;
&lt;h2&gt;Many of the tasks that must be automated are too challenging for current machine intelligence to consistently solve at a satisfactory level of performance. Hybrid intelligence where human intelligence is keept in the loop is thus a necessety for the forseable future. When applying hybrid intelligence there exisits two interaction patterns; active learning and hybrid interaction. In the former, human intelligence is only utilized when the machine isn't confident. In the latter both machine and human intelligence is involved in every case. Here the machine propose a solution that the human must accept, modify or reject. &lt;a href="https://medium.com/@clarecorthell/hybrid-artificial-intelligence-how-artificial-assistants-work-eefbafbd5334"&gt;Hybrid Intelligence: How Artificial Assistants Work&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;Transfer learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Taking a model trained for one task and fine-tuning it for use in a related task.&lt;/li&gt;
&lt;/ul&gt;</content><category term="machine learning"></category><category term="deep learning"></category><category term="reinforcement learning"></category><category term="transfer learning"></category><category term="continuous learning"></category></entry></feed>